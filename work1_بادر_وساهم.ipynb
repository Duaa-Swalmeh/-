{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eAlnjUsHGNb",
        "outputId": "fea267cf-9efd-4a8a-f1c2-d094d4b15172"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj-jUloQHd1m",
        "outputId": "13ce410c-5450-43cb-a22a-31adca274a37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "# --- Setup ---\n",
        "api_key = input(\" Enter your Groq API Key: \")\n",
        "llm = Groq(api_key=api_key)\n",
        "\n",
        "# Medical system prompt\n",
        "system_prompt = \"\"\"You are a professional virtual medical assistant.\n",
        "You provide accurate, safe, and step-by-step explanations for medical questions.\n",
        "Always include:\n",
        "1. A clear diagnosis or explanation.\n",
        "2. Possible causes.\n",
        "3. Recommended next steps or precautions.\n",
        "4. A disclaimer that this is not a substitute for a doctor's visit.\n",
        "\"\"\"\n",
        "\n",
        "continue_chat = True\n",
        "\n",
        "while continue_chat:\n",
        "    print(\"\\n--- Session Settings ---\")\n",
        "    temperature = 0.5\n",
        "    mode = input(\" Choose mode [0] Zero-shot:if you want Yes/No answer  or [1] One-shot: If you want a detailed answer\")\n",
        "\n",
        "    user_input = input(\" Enter your medical question: \")\n",
        "\n",
        "    # Prepare messages\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "    if mode == \"1\":  # One-shot example\n",
        "        example_question = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"I have a sore throat and mild fever. What could be the reason?\",\n",
        "        }\n",
        "        example_answer = {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"It could be a viral infection like the common cold or flu. Causes include viruses, bacteria, or allergies. Stay hydrated, rest, and consult a doctor if symptoms worsen. This is not a substitute for professional medical advice.\"\n",
        "        }\n",
        "        messages.append(example_question)\n",
        "        messages.append(example_answer)\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Call the LLM\n",
        "    response = llm.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",  # Supported model\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    # Print the reply\n",
        "    if mode == \"0\":  # Zero-shot -> simple Yes/No\n",
        "        print(\"\\n AI Medical Assistant:\\n\", \"Yes\" if \"yes\" in response.choices[0].message.content.lower() else \"No\")\n",
        "    else:\n",
        "        reply = response.choices[0].message.content\n",
        "        print(\"\\n AI Medical Assistant:\\n\", reply)\n",
        "\n",
        "    # Ask if the user wants another question\n",
        "    ask_again = input(\"\\n Do you want to ask another question? (yes/no): \").strip().lower()\n",
        "    if ask_again != \"yes\":\n",
        "        continue_chat = False\n",
        "        print(\" Goodbye!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urg9G9rhd5ui",
        "outputId": "faff8fe5-a140-4ce4-e6aa-1f8329190061"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Enter your Groq API Key: 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\n",
            "\n",
            "--- Session Settings ---\n",
            " Choose mode [0] Zero-shot:if you want Yes/No answer  or [1] One-shot: If you want a detailed answer0\n",
            " Enter your medical question: Can I take ibuprofen and paracetamol together?\n",
            "\n",
            " AI Medical Assistant:\n",
            " No\n",
            "\n",
            " Do you want to ask another question? (yes/no): yes\n",
            "\n",
            "--- Session Settings ---\n",
            " Choose mode [0] Zero-shot:if you want Yes/No answer  or [1] One-shot: If you want a detailed answer1\n",
            " Enter your medical question: Can I take ibuprofen and paracetamol together?\n",
            "\n",
            " AI Medical Assistant:\n",
            " I must advise against taking ibuprofen and paracetamol together without consulting a doctor. Both medications can cause stomach upset, bleeding, and kidney damage when taken together. Ibuprofen is a non-steroidal anti-inflammatory drug (NSAID) and paracetamol is an acetaminophen. Taking both can increase the risk of adverse effects.\n",
            "\n",
            "Instead, I recommend speaking with your doctor or pharmacist to determine the best course of treatment for your symptoms. They can help you choose the appropriate medication and dosage, taking into account your medical history and other health conditions.\n",
            "\n",
            "Remember, it's always better to err on the side of caution when it comes to your health. If you're unsure about taking any medications, consult with a healthcare professional for personalized advice.\n",
            "\n",
            "Disclaimer: This is not a substitute for professional medical advice. Always consult a doctor or pharmacist for personalized guidance on medication use.\n",
            "\n",
            " Do you want to ask another question? (yes/no): no\n",
            " Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from groq import Groq\n",
        "\n",
        "# --- Setup Groq LLM ---\n",
        "api_key = input(\"Enter your Groq API Key: \")\n",
        "llm = Groq(api_key=api_key)\n",
        "\n",
        "system_prompt = \"\"\"You are a professional virtual medical assistant.\n",
        "You provide accurate, safe, and step-by-step explanations for medical questions.\n",
        "Always include:\n",
        "1. A clear diagnosis or explanation.\n",
        "2. Possible causes.\n",
        "3. Recommended next steps or precautions.\n",
        "4. A disclaimer that this is not a substitute for a doctor's visit.\n",
        "\"\"\"\n",
        "\n",
        "TEMPERATURE = 0.5  # Fixed temperature\n",
        "\n",
        "def medical_chat(user_input, mode):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "    if mode == \"One-shot\":\n",
        "        example_question = {\"role\": \"user\", \"content\": \"I have a sore throat and mild fever. What could be the reason?\"}\n",
        "        example_answer = {\"role\": \"assistant\", \"content\": \"It could be a viral infection like the common cold or flu. Causes include viruses, bacteria, or allergies. Stay hydrated, rest, and consult a doctor if symptoms worsen. This is not a substitute for professional medical advice.\"}\n",
        "        messages.append(example_question)\n",
        "        messages.append(example_answer)\n",
        "\n",
        "    # For Zero-shot, force Yes/No response\n",
        "    if mode == \"Zero-shot\":\n",
        "        messages.append({\"role\": \"system\", \"content\": \"Answer the user's question with only 'Yes' or 'No', no explanation.\"})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = llm.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=messages,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    # Return Yes/No for Zero-shot, full response for One-shot\n",
        "    if mode == \"Zero-shot\":\n",
        "        answer_text = response.choices[0].message.content.strip().lower()\n",
        "        return \"Yes\" if \"yes\" in answer_text else \"No\"\n",
        "    else:\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"##  AI Medical Assistant Chatbot\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            user_input = gr.Textbox(label=\"Enter your medical question\")\n",
        "            mode = gr.Radio(choices=[\"Zero-shot\", \"One-shot\"], label=\"Mode\")\n",
        "            submit_btn = gr.Button(\"Ask\")\n",
        "        with gr.Column():\n",
        "            output = gr.Textbox(label=\"AI Response\", lines=20)\n",
        "\n",
        "    submit_btn.click(medical_chat, inputs=[user_input, mode], outputs=[output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "yupE9p_dg1_-",
        "outputId": "40142e3a-305b-4d6e-877b-529805786ce5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Groq API Key: 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\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7f949da6f357da2413.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7f949da6f357da2413.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}